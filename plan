# Day 1 — Prep & Terraform skeleton (foundation)

Goal: create the repo, initialize Terraform, and provision the VPC + subnets + IGW + route tables (the network foundation). This gets you a clean environment to build EKS on tomorrow.

What to do (exact steps)

Create the repo and folders:

mkdir project-bedrock
cd project-bedrock
git init
mkdir -p infrastructure/terraform k8s/manifests .github/workflows docs
echo -e "terraform.tfstate\n*.tfstate\n.terraform\n.terraform.lock.hcl\n*.tfvars\nsecrets/*" > .gitignore
git add . && git commit -m "repo skeleton"


Confirm AWS CLI + credentials:

aws sts get-caller-identity


If it returns your account, you’re good. If error, run aws configure (don’t commit keys).

Create Terraform provider + basic files (put in infrastructure/terraform/):

providers.tf (aws provider + required providers)

variables.tf (region, vpc CIDR)

vpc.tf (VPC, subnets, IGW, route tables — use the example I gave earlier)

outputs.tf (output VPC id and subnet ids)
(If you want I can paste exact file contents for these now.)

Init & apply only the VPC resources:

cd infrastructure/terraform
terraform init
terraform plan -out plan.vpc
terraform apply "plan.vpc"


Tip: If you prefer to only apply VPC resources and keep EKS for Day 2, keep the Terraform files limited to network resources for now.

Verify success

AWS CLI check:

aws ec2 describe-vpcs --filters "Name=tag:Name,Values=*bedrock*" --query 'Vpcs[*].{ID:VpcId,CIDR:CidrBlock}' --output table
aws ec2 describe-subnets --filters "Name=vpc-id,Values=<VPC_ID>" --output table


Console: VPC > Subnets > Route Tables should show the new ones.

What to commit (git)

infrastructure/terraform/*.tf (the TF files)

README.md with: Day1 summary + how you ran terraform apply and the outputs.

Notes & safety

Don’t commit any AWS credentials or terraform.tfstate. Add secrets/ to .gitignore.

If Terraform suggests creating lots of resources and you didn’t expect them, terraform destroy (in the same folder) will remove them.

# Day 2 — Create EKS cluster & deploy the app (in-cluster DBs)

Goal: provision EKS + node group, get kubeconfig, and deploy the retail-store sample app + in-cluster databases (MySQL, Postgres, Redis, RabbitMQ, DynamoDB-local) so the app runs inside the cluster.

What to do (exact steps)

Add EKS module to Terraform (in infrastructure/terraform/eks.tf) using terraform-aws-modules/eks/aws:

cluster name var

reference the VPC and private/public subnets created Day1

create a managed node group
(I can paste a ready eks.tf snippet if you want.)

Terraform apply for EKS:

terraform init      # if not already
terraform plan -out plan.eks
terraform apply "plan.eks"


Get kubeconfig:

aws eks update-kubeconfig --region <REGION> --name <CLUSTER_NAME>
kubectl get nodes


You should see worker nodes in Ready state.

Deploy the application manifests:

Put deployment/service YAMLs in k8s/manifests/ (ui, api, catalog, orders, carts).

Add DB manifests (or use Helm charts for Redis/RabbitMQ to make it easy):

# Example helm commands (on your laptop)
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install redis bitnami/redis
helm install rabbitmq bitnami/rabbitmq


Apply:

kubectl apply -f k8s/manifests/
kubectl get pods -A
kubectl get svc


Verify success

kubectl get pods -A — all retail microservice pods + DB pods should be Running or Completed.

kubectl logs <pod> — check one app pod for healthy startup logs.

kubectl get svc — check ClusterIP services; for UI you may expose NodePort for quick test (not production).

What to commit

k8s/manifests/* (deployments, services, secrets YAMLs)

Update README.md with cluster name, how to update-kubeconfig, and short verify commands.

Notes & cautions

Keep DB passwords out of the repo. Use Kubernetes secrets (created locally with kubectl create secret generic ...) — do not commit them.

If cluster creation fails due to IAM issues, ensure your Terraform role/user has required permissions (EKS, IAM, EC2).

# Day 3 — CI/CD + Developer read-only access + docs & polish

Goal: automate Terraform (plan on PR, apply on merge), create the developer read-only user for cluster viewing, finish the 2-page Deployment & Architecture guide, and push everything to GitHub.

What to do (exact steps)

Create GitHub repo and push local code:

git remote add origin git@github.com:<you>/project-bedrock.git
git push -u origin main


Add GitHub Actions workflow .github/workflows/terraform.yml (use OIDC role or least-privilege secrets). Example workflow (copy-paste from earlier I showed) — place that file now.

Configure AWS → GitHub OIDC:

Create an IAM role that trusts oidc-provider for your GitHub repo (if you want the secure path).

Put the role ARN into GitHub Secret AWS_OIDC_ROLE_ARN.
(If you prefer, use AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY as secrets — but rotate later.)

Set up developer read-only access for Kubernetes:

Create IAM user (example):

aws iam create-user --user-name dev-readonly
aws iam create-access-key --user-name dev-readonly  # save securely


Map the IAM user to a Kubernetes username in aws-auth:

kubectl get configmap aws-auth -n kube-system -o yaml > /tmp/aws-auth.yaml
# add under data.mapUsers:
# - userarn: arn:aws:iam::<ACCOUNT_ID>:user/dev-readonly
#   username: dev-readonly
#   groups: ["dev-readonly-group"]
kubectl apply -f /tmp/aws-auth.yaml


Give the user the Kubernetes view role:

kubectl create clusterrolebinding dev-readonly-view --clusterrole=view --user=dev-readonly


Provide developer instructions (in docs/DEPLOYMENT_GUIDE.md) for aws configure and aws eks update-kubeconfig to get their kube access.

Final docs and submission artifacts:

docs/DEPLOYMENT_GUIDE.md — 2 pages max: architecture diagram (simple ASCII or brief list), how to access app, credentials & kubeconfig instructions for dev user, CI/CD notes, and any bonus work details.

README summary & repo link.

Verify success

Open a PR on GitHub: see GitHub Actions run terraform plan.

Merge to main: verify Actions triggers terraform apply. (If you used OIDC role, observe it assumes role.)

As dev user: follow provided steps to fetch kubeconfig and run kubectl get pods -A — you should see read-only access only (no apply/delete).

What to commit

.github/workflows/terraform.yml

docs/DEPLOYMENT_GUIDE.md

README.md polished

Any helper scripts (e.g., scripts/create_dev_user.sh) — but be careful not to include private keys.

Bonus (optional)

If you want the ALB + HTTPS + Route53, add the AWS Load Balancer Controller and create Ingress with ACM cert — but treat as an extra step after the 3 days.

Quick safety & cost reminders (do these now)

After each day, run terraform destroy in your TF folder if you want to tear it down. Don’t leave EKS running if you’re not using it.

Check Billing dashboard to ensure nothing unexpected is charging.

Never commit secrets or AWS keys into git.